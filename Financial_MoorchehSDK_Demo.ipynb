{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Install Necessary Packages**"
      ],
      "metadata": {
        "id": "5A0GrIL81owo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install moorcheh-sdk langchain_community pypdf pandas"
      ],
      "metadata": {
        "id": "wzIB2BXtjzLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22305440-2d6d-49cb-b7e9-44d81b3a774c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: moorcheh-sdk in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.7.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: httpx<0.29.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from moorcheh-sdk) (0.28.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.67)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.26)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.4)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.1->moorcheh-sdk) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.1->moorcheh-sdk) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.1->moorcheh-sdk) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.1->moorcheh-sdk) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29.0,>=0.28.1->moorcheh-sdk) (0.16.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.14.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29.0,>=0.28.1->moorcheh-sdk) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import pandas as pd\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import time\n",
        "from sentence_transformers import SentenceTransformer  # Optional: Can be used for embedding\n",
        "from google.colab import userdata\n",
        "from moorcheh_sdk import MoorchehClient"
      ],
      "metadata": {
        "id": "3DpNobtoJmk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initalize the MoorchehClient**"
      ],
      "metadata": {
        "id": "9TJoqNTE2pYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MOORCHEH_API_KEY = userdata.get(\"MOORCHEH_API_KEY\")\n",
        "\n",
        "namespace_name=\"new_namepsaces\"\n",
        "client = MoorchehClient(api_key=MOORCHEH_API_KEY)\n",
        "client.create_namespace(namespace_name=namespace_name, type=\"text\")\n",
        "\n",
        "pdf_path = \"CombinedDoc.pdf\"\n",
        "query_csv_path = \"queries.csv\" # Path to your CSV file with queries\n",
        "output_csv_path = \"answers.csv\" # Where to save the results\n",
        "top_k = 5"
      ],
      "metadata": {
        "id": "H7moPQS2JtbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prepare and Chunk the Documents**"
      ],
      "metadata": {
        "id": "wUPS4svI3JhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(pdf_path)\n",
        "pages = loader.load()\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=120)\n",
        "chunks = splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "cZTaj3m4KZNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Upload the Document Chunks**"
      ],
      "metadata": {
        "id": "Ik1auvyq3QhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = []\n",
        "for i, chunk in enumerate(chunks):\n",
        "    text = chunk.page_content.strip()\n",
        "    documents.append({\"id\": f\"chunk_{i}\",\n",
        "                      \"text\": text})\n",
        "\n",
        "client.upload_documents(namespace_name=namespace_name, documents=documents)"
      ],
      "metadata": {
        "id": "prkKIGeoLIxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece128f0-d7ec-4ea7-a219-18d0e3370012",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'success',\n",
              " 'message': 'Successfully queued 211 documents for processing.',\n",
              " 'queued_documents': 211,\n",
              " 'document_ids': ['chunk_0',\n",
              "  'chunk_1',\n",
              "  'chunk_2',\n",
              "  'chunk_3',\n",
              "  'chunk_4',\n",
              "  'chunk_5',\n",
              "  'chunk_6',\n",
              "  'chunk_7',\n",
              "  'chunk_8',\n",
              "  'chunk_9',\n",
              "  'chunk_10',\n",
              "  'chunk_11',\n",
              "  'chunk_12',\n",
              "  'chunk_13',\n",
              "  'chunk_14',\n",
              "  'chunk_15',\n",
              "  'chunk_16',\n",
              "  'chunk_17',\n",
              "  'chunk_18',\n",
              "  'chunk_19',\n",
              "  'chunk_20',\n",
              "  'chunk_21',\n",
              "  'chunk_22',\n",
              "  'chunk_23',\n",
              "  'chunk_24',\n",
              "  'chunk_25',\n",
              "  'chunk_26',\n",
              "  'chunk_27',\n",
              "  'chunk_28',\n",
              "  'chunk_29',\n",
              "  'chunk_30',\n",
              "  'chunk_31',\n",
              "  'chunk_32',\n",
              "  'chunk_33',\n",
              "  'chunk_34',\n",
              "  'chunk_35',\n",
              "  'chunk_36',\n",
              "  'chunk_37',\n",
              "  'chunk_38',\n",
              "  'chunk_39',\n",
              "  'chunk_40',\n",
              "  'chunk_41',\n",
              "  'chunk_42',\n",
              "  'chunk_43',\n",
              "  'chunk_44',\n",
              "  'chunk_45',\n",
              "  'chunk_46',\n",
              "  'chunk_47',\n",
              "  'chunk_48',\n",
              "  'chunk_49',\n",
              "  'chunk_50',\n",
              "  'chunk_51',\n",
              "  'chunk_52',\n",
              "  'chunk_53',\n",
              "  'chunk_54',\n",
              "  'chunk_55',\n",
              "  'chunk_56',\n",
              "  'chunk_57',\n",
              "  'chunk_58',\n",
              "  'chunk_59',\n",
              "  'chunk_60',\n",
              "  'chunk_61',\n",
              "  'chunk_62',\n",
              "  'chunk_63',\n",
              "  'chunk_64',\n",
              "  'chunk_65',\n",
              "  'chunk_66',\n",
              "  'chunk_67',\n",
              "  'chunk_68',\n",
              "  'chunk_69',\n",
              "  'chunk_70',\n",
              "  'chunk_71',\n",
              "  'chunk_72',\n",
              "  'chunk_73',\n",
              "  'chunk_74',\n",
              "  'chunk_75',\n",
              "  'chunk_76',\n",
              "  'chunk_77',\n",
              "  'chunk_78',\n",
              "  'chunk_79',\n",
              "  'chunk_80',\n",
              "  'chunk_81',\n",
              "  'chunk_82',\n",
              "  'chunk_83',\n",
              "  'chunk_84',\n",
              "  'chunk_85',\n",
              "  'chunk_86',\n",
              "  'chunk_87',\n",
              "  'chunk_88',\n",
              "  'chunk_89',\n",
              "  'chunk_90',\n",
              "  'chunk_91',\n",
              "  'chunk_92',\n",
              "  'chunk_93',\n",
              "  'chunk_94',\n",
              "  'chunk_95',\n",
              "  'chunk_96',\n",
              "  'chunk_97',\n",
              "  'chunk_98',\n",
              "  'chunk_99',\n",
              "  'chunk_100',\n",
              "  'chunk_101',\n",
              "  'chunk_102',\n",
              "  'chunk_103',\n",
              "  'chunk_104',\n",
              "  'chunk_105',\n",
              "  'chunk_106',\n",
              "  'chunk_107',\n",
              "  'chunk_108',\n",
              "  'chunk_109',\n",
              "  'chunk_110',\n",
              "  'chunk_111',\n",
              "  'chunk_112',\n",
              "  'chunk_113',\n",
              "  'chunk_114',\n",
              "  'chunk_115',\n",
              "  'chunk_116',\n",
              "  'chunk_117',\n",
              "  'chunk_118',\n",
              "  'chunk_119',\n",
              "  'chunk_120',\n",
              "  'chunk_121',\n",
              "  'chunk_122',\n",
              "  'chunk_123',\n",
              "  'chunk_124',\n",
              "  'chunk_125',\n",
              "  'chunk_126',\n",
              "  'chunk_127',\n",
              "  'chunk_128',\n",
              "  'chunk_129',\n",
              "  'chunk_130',\n",
              "  'chunk_131',\n",
              "  'chunk_132',\n",
              "  'chunk_133',\n",
              "  'chunk_134',\n",
              "  'chunk_135',\n",
              "  'chunk_136',\n",
              "  'chunk_137',\n",
              "  'chunk_138',\n",
              "  'chunk_139',\n",
              "  'chunk_140',\n",
              "  'chunk_141',\n",
              "  'chunk_142',\n",
              "  'chunk_143',\n",
              "  'chunk_144',\n",
              "  'chunk_145',\n",
              "  'chunk_146',\n",
              "  'chunk_147',\n",
              "  'chunk_148',\n",
              "  'chunk_149',\n",
              "  'chunk_150',\n",
              "  'chunk_151',\n",
              "  'chunk_152',\n",
              "  'chunk_153',\n",
              "  'chunk_154',\n",
              "  'chunk_155',\n",
              "  'chunk_156',\n",
              "  'chunk_157',\n",
              "  'chunk_158',\n",
              "  'chunk_159',\n",
              "  'chunk_160',\n",
              "  'chunk_161',\n",
              "  'chunk_162',\n",
              "  'chunk_163',\n",
              "  'chunk_164',\n",
              "  'chunk_165',\n",
              "  'chunk_166',\n",
              "  'chunk_167',\n",
              "  'chunk_168',\n",
              "  'chunk_169',\n",
              "  'chunk_170',\n",
              "  'chunk_171',\n",
              "  'chunk_172',\n",
              "  'chunk_173',\n",
              "  'chunk_174',\n",
              "  'chunk_175',\n",
              "  'chunk_176',\n",
              "  'chunk_177',\n",
              "  'chunk_178',\n",
              "  'chunk_179',\n",
              "  'chunk_180',\n",
              "  'chunk_181',\n",
              "  'chunk_182',\n",
              "  'chunk_183',\n",
              "  'chunk_184',\n",
              "  'chunk_185',\n",
              "  'chunk_186',\n",
              "  'chunk_187',\n",
              "  'chunk_188',\n",
              "  'chunk_189',\n",
              "  'chunk_190',\n",
              "  'chunk_191',\n",
              "  'chunk_192',\n",
              "  'chunk_193',\n",
              "  'chunk_194',\n",
              "  'chunk_195',\n",
              "  'chunk_196',\n",
              "  'chunk_197',\n",
              "  'chunk_198',\n",
              "  'chunk_199',\n",
              "  'chunk_200',\n",
              "  'chunk_201',\n",
              "  'chunk_202',\n",
              "  'chunk_203',\n",
              "  'chunk_204',\n",
              "  'chunk_205',\n",
              "  'chunk_206',\n",
              "  'chunk_207',\n",
              "  'chunk_208',\n",
              "  'chunk_209',\n",
              "  'chunk_210'],\n",
              " 'execution_time': 11.96}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generate Answer**"
      ],
      "metadata": {
        "id": "HyW7Q7W13UQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries_df = pd.read_csv(query_csv_path) # Load your questions from a CSV file\n",
        "\n",
        "with open(output_csv_path, \"w\", newline=\"\") as f: # Open the results CSV file\n",
        "    writer = csv.DictWriter(f, fieldnames=[\"passage_id\", \"query\", \"generated_answers\"]) # Set up CSV columns\n",
        "    writer.writeheader() # Write the column headers\n",
        "\n",
        "    for idx, q in enumerate(queries_df[\"query\"]): # Go through each question\n",
        "        print(f\"Processing: {q}\") # Show which question is being processed\n",
        "        try:\n",
        "            response = client.get_generative_answer(query = q,\n",
        "                                               ai_model = \"anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
        "                                               namespace=namespace_name).get(\"answer\", \"\")\n",
        "            time.sleep(0.5)\n",
        "            writer.writerow({ # Write the results to the CSV\n",
        "                \"passage_id\": idx, # Unique ID for this answer\n",
        "                \"query\": q, # The original question\n",
        "                \"generated_answers\": response # The AI-generated answer\n",
        "            })\n",
        "        except Exception as e: # If something goes wrong\n",
        "            print(f\"Error for query '{q}':\", e) # Print the error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoSm9E_ZmqgM",
        "outputId": "cd264b79-9c42-4a95-8cc9-9b4ecb5bebdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: What is Meta’s Net Income in 2025?\n",
            "Processing: What is Netflix’s Profit in 2025?\n",
            "Processing: What is Apple’s Expenses in 2025?\n",
            "Processing: What is Alphabet’s Revenue in 2025?\n",
            "Processing: What is Amazon’s operating expenses in 2025?\n",
            "Processing: Which company had the highest revenue in the first quarter of 2025?\n",
            "Processing: Which company has seen the least growth?\n",
            "Processing: Which of the five companies showed the strongest overall financial performance in early 2025 and why?\n",
            "Processing: Compare the quarter-on-quarter revenue growth between Meta and Alphabet.\n",
            "Processing: Compare the quarter-on-quarter revenue growth between Netflix and Amazon.\n"
          ]
        }
      ]
    }
  ]
}