{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Install Necessary Packages**"
      ],
      "metadata": {
        "id": "Tk9Cwe0TdmZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install firecrawl-py\n",
        "!pip install moorcheh-sdk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAEBFcuRVEIn",
        "outputId": "9a0a62a0-b174-4fbe-b32a-da1c5183b90f",
        "collapsed": true
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: firecrawl-py in /usr/local/lib/python3.11/dist-packages (2.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from firecrawl-py) (2.32.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from firecrawl-py) (1.1.1)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from firecrawl-py) (15.0.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from firecrawl-py) (1.6.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from firecrawl-py) (2.11.7)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from firecrawl-py) (3.11.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->firecrawl-py) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->firecrawl-py) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->firecrawl-py) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->firecrawl-py) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->firecrawl-py) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->firecrawl-py) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->firecrawl-py) (1.20.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->firecrawl-py) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->firecrawl-py) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->firecrawl-py) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->firecrawl-py) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->firecrawl-py) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->firecrawl-py) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->firecrawl-py) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->firecrawl-py) (2025.7.14)\n",
            "Requirement already satisfied: moorcheh-sdk in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: httpx<0.29.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from moorcheh-sdk) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.1->moorcheh-sdk) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.1->moorcheh-sdk) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.1->moorcheh-sdk) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.1->moorcheh-sdk) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29.0,>=0.28.1->moorcheh-sdk) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29.0,>=0.28.1->moorcheh-sdk) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29.0,>=0.28.1->moorcheh-sdk) (4.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Packages**"
      ],
      "metadata": {
        "id": "4IuhoC8rdy4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import time\n",
        "import logging\n",
        "from typing import List\n",
        "import pandas as pd\n",
        "from firecrawl import FirecrawlApp\n",
        "from moorcheh_sdk import MoorchehClient\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "-npq5fGELAYM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preparation Variables Setup**"
      ],
      "metadata": {
        "id": "QR4-u3uLeMXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Logging ---\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# --- API Keys ---\n",
        "FIRECRAWL_API_KEY = userdata.get(\"FIRECRAWL_API_KEY\")\n",
        "MOORCHEH_API_KEY = userdata.get(\"MOORCHEH_API_KEY\")\n",
        "\n",
        "if not FIRECRAWL_API_KEY or not MOORCHEH_API_KEY:\n",
        "    raise EnvironmentError(\"Missing FIRECRAWL_API_KEY or MOORCHEH_API_KEY\")\n",
        "\n",
        "# --- Initialize Clients ---\n",
        "firecrawl_app = FirecrawlApp(api_key=FIRECRAWL_API_KEY)\n",
        "moorcheh_client = MoorchehClient(api_key=MOORCHEH_API_KEY)\n",
        "\n",
        "# --- Config ---\n",
        "NAMESPACE = \"moorcheh_website\"\n",
        "NAMESPACE_TYPE = \"text\"\n",
        "VECTOR_DIM = None\n",
        "QUERY_CSV = \"queries.csv\"\n",
        "OUTPUT_CSV = \"answers.csv\"\n",
        "SCRAPE_URLS = [\"https://www.moorcheh.ai/about\"]\n",
        "AI_MODEL = \"anthropic.claude-3-7-sonnet-20250219-v1:0\""
      ],
      "metadata": {
        "id": "YLKmZKgBfJ86"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Scraping and Batch Uploading Functions**"
      ],
      "metadata": {
        "id": "6lB3pUnGfO1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Scrape and Chunk ---\n",
        "def scrape_and_chunk(urls: List[str], min_len: int = 20) -> List[dict]:\n",
        "    chunks = []\n",
        "    for url in urls:\n",
        "        result = firecrawl_app.scrape_url(url)\n",
        "        content = result.markdown\n",
        "        for i, sentence in enumerate(content.split(\".\")):\n",
        "            sentence = sentence.strip()\n",
        "            if len(sentence) > min_len:\n",
        "                chunks.append({\n",
        "                    \"id\": f\"{NAMESPACE}-{i}\",\n",
        "                    \"text\": sentence,\n",
        "                    \"metadata\": {\"source\": url}\n",
        "                })\n",
        "    return chunks\n",
        "\n",
        "# --- Upload in Batches  ---\n",
        "def upload_in_batches(client, namespace_name, documents, batch_size=100):\n",
        "    total = len(documents)\n",
        "    for i in range(0, total, batch_size):\n",
        "        batch = documents[i:i+batch_size]\n",
        "        logging.info(f\"Uploading batch {i//batch_size + 1}: {len(batch)} documents\")\n",
        "        client.upload_documents(namespace_name=namespace_name, documents=batch)\n",
        "        time.sleep(0.2)\n",
        "\n",
        "\n",
        "logging.info(\"Scraping content...\")\n",
        "documents = scrape_and_chunk(SCRAPE_URLS)"
      ],
      "metadata": {
        "id": "MLV_PwUNfq2B"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Upload Documents to Moorcheh Namespace**"
      ],
      "metadata": {
        "id": "Ya6Uemp4gMf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Upload to Moorcheh ---\n",
        "logging.info(f\"Creating namespace '{NAMESPACE}' and uploading {len(documents)} chunks...\")\n",
        "\n",
        "moorcheh_client.create_namespace(namespace_name=NAMESPACE, type=NAMESPACE_TYPE, vector_dimension=VECTOR_DIM)\n",
        "upload_in_batches(\n",
        "    client=moorcheh_client,\n",
        "    namespace_name=NAMESPACE,\n",
        "    documents=documents,\n",
        "    batch_size=100\n",
        ")"
      ],
      "metadata": {
        "id": "VUAoVnMHeIbB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Run Queries**"
      ],
      "metadata": {
        "id": "h_QjWiIOgUL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Run Queries ---\n",
        "if not os.path.exists(QUERY_CSV):\n",
        "    raise FileNotFoundError(f\"Missing: {QUERY_CSV}\")\n",
        "\n",
        "queries_df = pd.read_csv(QUERY_CSV)\n",
        "\n",
        "with open(OUTPUT_CSV, \"w\", newline=\"\") as f:\n",
        "    writer = csv.DictWriter(f, fieldnames=[\"passage_id\", \"query\", \"generated_answers\"])\n",
        "    writer.writeheader()\n",
        "\n",
        "    for idx, row in queries_df.iterrows():\n",
        "        query = row[\"query\"]\n",
        "        logging.info(f\"Query {idx + 1}: {query}\")\n",
        "        try:\n",
        "            response = moorcheh_client.get_generative_answer(\n",
        "                namespace=NAMESPACE,\n",
        "                query=query,\n",
        "                ai_model=AI_MODEL\n",
        "            )\n",
        "            writer.writerow({\n",
        "                \"passage_id\": idx,\n",
        "                \"query\": query,\n",
        "                \"generated_answers\": response.get(\"answer\", \"No answer.\")\n",
        "            })\n",
        "            time.sleep(0.5)\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error for query '{query}': {e}\")\n",
        "            writer.writerow({\n",
        "                \"passage_id\": idx,\n",
        "                \"query\": query,\n",
        "                \"generated_answers\": f\"ERROR: {e}\"\n",
        "            })"
      ],
      "metadata": {
        "id": "0HbpAWfZgWzf"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}
